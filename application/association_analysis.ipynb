{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload imports on cell execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = \"/home/mbernstorff/miniconda3/envs/antihypertensives/\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/home/mbernstorff/cprd-antihypertensives\")\n",
    "from cprd_antihypertensives.cprd.utils.yaml_act import yaml_load\n",
    "from cprd_antihypertensives.cprd.config.spark import spark_init, read_parquet\n",
    "from cprd_antihypertensives.cprd.functions import tables\n",
    "from cprd_antihypertensives.cprd.functions.MedicalDictionary import *\n",
    "from cprd_antihypertensives.cprd.functions.Prediction import *\n",
    "from cprd_antihypertensives.cprd.functions.cohort_select_causal import *\n",
    "\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cprd_antihypertensives.globals import PROJECT_ROOT\n",
    "\n",
    "\n",
    "config = yaml_load(\n",
    "    dotdict({\"params\": PROJECT_ROOT / \"application\" / \"config\" / \"config.yaml\"}).params\n",
    ")\n",
    "\n",
    "config[\"pyspark\"][\"pyspark_env\"]\n",
    "\n",
    "pyspark_config = config[\"pyspark\"]\n",
    "spark_instance = spark_init(pyspark_config)\n",
    "\n",
    "file_paths = config[\"file_path\"]\n",
    "current_params = config[\"params\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort selection\n",
    "### Effect of antihypertensives on ischaemic conditions\n",
    "\n",
    "- Cohort selection: Age between 60 and 61 years in years between 2009 and 2010\n",
    "\n",
    "- Baseline: First initiation of any antihypertensive\n",
    "\n",
    "- Take random baseline for those without any antihypertensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical dict can give us both exposures and outcomes codes - e.g. diabetes as outcomes or antihyyp as exposurea\n",
    "md = MedicalDictionaryRiskPrediction(file_paths, spark_instance)\n",
    "antihypertensive_product_codes = md.queryMedication(md.findItem(\"antihy\"), merge=True)[\n",
    "    \"merged\"\n",
    "]\n",
    "expcodes = {\"prodcode\": antihypertensive_product_codes}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exposure selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CohortSoftCut from the causal cohort selection package has everything to select cohort and baseline\n",
    "# specifically the baseline for those WITH the exposure is date of exposure, and for those WITHOUT exp of interest is random sampling of baseline\n",
    "cohortSelector = CohortSoftCut(\n",
    "    least_year_register_gp=1,\n",
    "    least_age=60,\n",
    "    greatest_age=61,\n",
    "    exposure=expcodes,\n",
    "    imdReq=False,\n",
    "    linkage=False,\n",
    "    practiceLink=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no mapping as you don't want to drop the prodcodes which are not mapped...\n",
    "# medications = retrieve_medications(file, spark, mapping='none', duration=(2009, 2010), demographics=cohort, practiceLink=True)\n",
    "# medications.write.parquet('/home/shared/shishir/AurumOut/rawDat/meds_nomapping_2009_2010_association_example.parquet')\n",
    "\n",
    "medications = read_parquet(\n",
    "    spark_instance.sqlContext,\n",
    "    \"/home/shared/shishir/AurumOut/rawDat/meds_nomapping_2009_2010_association_example.parquet\",\n",
    ")\n",
    "# medications.select('patid').dropDuplicates().count()  - 208603 patients have meds in the time period\n",
    "# medications.select('patid').count() - 11764962 number of records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline() function has 3 components:\n",
    "1) Demo extract gets eligible patients between age 60 and 61 ^ defined above and years 2009 and 2010  \n",
    "2) Extraction of the exposure of interest -  set  baseline as the date of the exposure  \n",
    "3) For those without exposure (i.e. control patients), set up baseline as randomised baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohortSelector.pipeline(\n",
    "    file=file_paths,\n",
    "    spark=spark_instance,\n",
    "    duration=(\"2009-01-01\", \"2010-01-01\"),\n",
    "    randomNeg=True,\n",
    "    sourceT=medications,\n",
    "    sourceCol=\"prodcode\",\n",
    "    rollingTW=-1,\n",
    ")\n",
    "cohort.write.parquet(\n",
    "    \"/home/shared/shishir/AurumOut/rawDat/cohort_association_example.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = read_parquet(\n",
    "    spark_instance.sqlContext,\n",
    "    \"/home/shared/shishir/AurumOut/rawDat/cohort_association_example.parquet\",\n",
    ")\n",
    "cohort.count()\n",
    "# 259345 pats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outcome selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = read_parquet(\n",
    "    spark_instance.sqlContext,\n",
    "    \"/home/shared/shishir/AurumOut/rawDat/cohort_association_example.parquet\",\n",
    ")\n",
    "\n",
    "necessaryColumns = [\n",
    "    \"patid\",\n",
    "    \"gender\",\n",
    "    \"dob\",\n",
    "    \"study_entry\",\n",
    "    \"startdate\",\n",
    "    \"enddate\",\n",
    "    \"exp_label\",\n",
    "]\n",
    "\n",
    "cohort = cohort.select(necessaryColumnsaryColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label codes phenotyping from medical dict - ie maybe ischaemic conditions\n",
    "labelcodes = md.queryDisease(md.findItem(\"ischaem\"), merge=True)[\"merged\"]\n",
    "allIschaemiaCodes = labelcodes[\"medcode\"] + labelcodes[\"ICD10\"] + labelcodes[\"OPCS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label codes phenotyping from medical dict - ie maybe ischaemic conditions\n",
    "\n",
    "# split diags into icd and nonicd(medcode) and re-union as \"code\"\n",
    "allDiag = read_parquet(\n",
    "    spark_instance.sqlContext,\n",
    "    \"/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet\",\n",
    ")\n",
    "GPdiags = allDiag[allDiag.source == \"CPRD\"]\n",
    "GPdiags = GPdiags.select([\"patid\", \"eventdate\", \"medcode\"]).withColumnRenamed(\n",
    "    \"medcode\", \"code\"\n",
    ")\n",
    "HESdiags = allDiag[allDiag.source == \"HES\"]\n",
    "HESdiags = HESdiags.select([\"patid\", \"eventdate\", \"ICD\"]).withColumnRenamed(\n",
    "    \"ICD\", \"code\"\n",
    ")\n",
    "allDiag = GPdiags.union(HESdiags)\n",
    "\n",
    "# read death registry as death is an important data source for looking for outcome\n",
    "death = tables.retrieve_death(dir=file_paths[\"death\"], spark=spark_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use the risk prediction label capture class\n",
    "# basically with baseline we can capture 1) outcome, 2) time to outcome\n",
    "\n",
    "# the exclusion_codes is those we should exclude based on condition - i.e., exclude those with prior cancers\n",
    "# the duration is time we should consider the records in the outcome space (maybe from 2008 since earliest baseline is 2009 and end is 2020)\n",
    "# the follow_up_duration_month is number of months for the followup\n",
    "# the time_to_event_mark_default is mark as -1 if no event and lasts till end of follow-up\n",
    "# more information in package\n",
    "risk_pred_generator = OutcomePrediction(\n",
    "    label_condition=allIschaemiaCodes,\n",
    "    exclusion_codes=None,\n",
    "    duration=(2008, 2020),\n",
    "    follow_up_duration_month=24,\n",
    "    time_to_event_mark_default=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographics is the cohort file with sutdy entry etc\n",
    "# source is the diag table\n",
    "# source_col is column that has the diags\n",
    "# exclusion_source is True if we want to exclude based on past diags\n",
    "\n",
    "# check_death is true if we are to check death\n",
    "# column_condition is column that has the diags or meds or whatever modality we are wanting to look for label\n",
    "# incidence is True if we are looking for incident lable\n",
    "# prevalent_conditions is if incidence is false, then what are some prevalent conditions we are allowing to look for (a subset of the labels)\n",
    "# more information in package\n",
    "\n",
    "\n",
    "risk_cohort = risk_pred_generator.pipeline(\n",
    "    demographics=cohort,\n",
    "    source=allDiag,\n",
    "    exclusion_source=False,\n",
    "    check_death=True,\n",
    "    death=death,\n",
    "    column_condition=\"code\",\n",
    "    incidence=True,\n",
    "    prevalent_conditions=None,\n",
    ")\n",
    "\n",
    "\n",
    "risk_cohort.write.parquet(\"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cprd-antihypertensives",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
